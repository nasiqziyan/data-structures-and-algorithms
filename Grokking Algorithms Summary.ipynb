{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf63524-f131-4eb4-b2f9-e0f859dd8e5d",
   "metadata": {},
   "source": [
    "Preamble: These are often considered the fundamentals of DSA\n",
    "- Linked Lists \n",
    "- Stacks \n",
    "- Queues\n",
    "- Trees \n",
    "- Graphs \n",
    "- Heaps\n",
    "- Hash tables\n",
    "\n",
    "This book is extremely introductory on all of these concepts, but doesn't cover heaps, trees, queues or stacks in any practical detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d9dc4-b88a-4e28-851a-24555dbc0b6c",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6cc880-8297-4b42-9bb9-63bb971222d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Binary search (Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395aa6e-0e65-41ca-bb17-75315b40b4cd",
   "metadata": {},
   "source": [
    "In general, for any list of n, binary search will take **log2(n)** steps to run in the worst case, whereas simple search will take **n** steps. So if a phone book contains 128 entries **in order**, it will take a maximum of **log2(128) = 7 steps**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e7da529-aa8e-4ff7-b94f-47aa7d9481a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_iterative(list, item):\n",
    "    # low and high keep track of which part of the list you'll search in.\n",
    "    low = 0\n",
    "    high = len(list) - 1\n",
    "\n",
    "    # While you haven't narrowed it down to one element ...\n",
    "    while low <= high:\n",
    "        # ... check the middle element\n",
    "        mid = (low + high) // 2\n",
    "        guess = list[mid]\n",
    "        \n",
    "        # Found the item.\n",
    "        if guess == item:\n",
    "            return mid\n",
    "        \n",
    "        # The guess was too high.\n",
    "        if guess > item:\n",
    "            high = mid - 1\n",
    "            \n",
    "        # The guess was too low.\n",
    "        else:\n",
    "            low = mid + 1\n",
    "\n",
    "    # Item doesn't exist\n",
    "    return None\n",
    "\n",
    "# item is the value in our list that we're looking for.\n",
    "\n",
    "search_iterative([1, 3, 5, 7, 9], item=3) # we are looking for the number 3 in our list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d4514-da11-4bbf-b4d1-91ff46b785f9",
   "metadata": {},
   "source": [
    "So we find the middle of the list then guess to see if the corresponding element is our item. If the guess is too low we raise the lower bound to be the middle of the list, and vice versa. Binary search runs in `O(logn)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e0b7e8-c926-414d-9ed4-90184ede1c36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Big O notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a991cb1-2a13-4e0b-a068-e454033306e7",
   "metadata": {},
   "source": [
    "There are 5 common Big O runtimes.\n",
    "\n",
    "* O(log n), also known as log time. Example: Binary search.\n",
    "* O(n), also known as linear time. Example: Simple search.\n",
    "* O(n * log n). Example: A fast sorting algorithm, like quicksort\n",
    "* O(n2). Example: A slow sorting algorithm, like selection sort\n",
    "* O(n!). Example: A really slow algorithm, like the traveling salesperson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc5235-6a5b-48ae-92e9-f00c2a9eda13",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305783b6-b3e0-4724-8da9-9b48dd50cde2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How Memory Works, Arrays and Linked Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f4829-298e-49a7-8387-597869fa5e2c",
   "metadata": {},
   "source": [
    "Picture 'memory' as a large checker box with an address for each box. If you want to store more than one item in memory, there are two ways of going about it - arrays and linked lists.\n",
    "\n",
    "- Array: If you have a todo list, all tasks are stored contiguously (right next to each other) in memory. If there's only 4 adjacent addresses available and you have 5 items that you want to store, the computer will find a location with 5 addresses free, and will move all your items there. If you need more spaces and don't have it available, you'll have to move again. **Adding** more items to arrays is slow. Linked lists are the solution.\n",
    "\n",
    "- Linked lists: Each item stores the address of the next item in the list. A bunch of random memory addresses are linked together. So, the 1st address gives the position of the 2nd address, and the 2nd address gives the position of the 3rd address and so on. **Adding** more items to linked lists is fast. You simply choose any random address, make note of it and then add your item. Then, give your previous address the location you just noted down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d2f43-120b-4061-ad39-edc80dbda52d",
   "metadata": {},
   "source": [
    "So what are arrays good for? \n",
    "\n",
    "If you have a list of 10 items in a linked list and want to know the final one, you will have to go from 1 to 2 to 3 to ... 10. **Linked lists are bad if you're jumping around**.\n",
    "\n",
    "With arrays, on the other hand, if you want the 5th item and you know the first address starts at 0x0000, then the 5th address is 0x0004. Arrays are great if you want to read random elements, because you can look up any element in your array instantly. Here are their runtimes:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/1.png width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641aa35b-a751-45b0-bdce-b0cf8d39f64a",
   "metadata": {},
   "source": [
    "Note that because linked lists have read: O(n), if you intend on reading every element then O(n) is the fastest way of doing that. (This is because, if you want to read all n elements, then it must take at least n reads and therefore, O(n). It's only when doing random jumps that linked lists suffer the most with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58e0b8-e604-41d9-b961-c08851abd5af",
   "metadata": {},
   "source": [
    "**Inserting to the middle of a list**\n",
    "\n",
    "Doing this with linked lists is easy: You find the middle address (hard) and you redirect the previous address to point to your new middle item (easy). With an array, you need to shift all items down one slot. If you run out of space, you'll have to copy everything to a new location. \n",
    "\n",
    "The reason why array insertions take linear time (O(n)) is because the number of elements you have to move when you insert a value is proportional to the length of the array. For the purposes of Big-O you can consider the worst case (insert it at the beginning means you have to move all N existing elements), or on average for a random place within the array , about N/2. Whichever way you look at it, it is proportional to N, and thus linear, as opposed to logarithmic or some other power of N.\n",
    "\n",
    "**Deleting a middle element of a list**\n",
    "\n",
    "Exact same idea as above. Linked lists make it easy because you redirect the pointer. With arrays, you have to shift everything back one slot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed419e03-e3cd-4f54-9659-8a2af07d1a80",
   "metadata": {},
   "source": [
    "Here are the runtimes:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/2.png width=500 />\n",
    "\n",
    "It's worth mentioning that for the O(1) runtimes, we assume that we can instantly access the element. We know that in reality, for a linked list, we must iterate sequentially until we reach the element that we want to delete/insert into. **Since we normally insert or append, it is extremely useful to know the first address (to speed up inserting) and the last address (to speed up appending), therefore computers do this. This is why inserting is so fast with linked lists, we can safely assume that we know the last item in a linked list, so to append one item, all we've got to do is give the address of our appended item to our last item.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11e703b-6933-4ca6-8db6-28fe554df675",
   "metadata": {},
   "source": [
    "To summarise:\n",
    "\n",
    "- **Linked lists only allow sequential access**\n",
    "- **Arrays allow random access** - we often say arrays have faster reads because they provide random access. If you want to read a random element, tell a software to think of a random number and use that to look up any element in your array instantly.\n",
    "\n",
    "Many data structures are implemented using arrays because of random access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e1df7-bf88-4c52-a2e2-5ab13b8612bd",
   "metadata": {},
   "source": [
    "Extra points:\n",
    "\n",
    "- Doubly linked list has nodes that also reference the previous node. \n",
    "- Circularly linked list is simply a linked list whose tail, the last node, references the head, the first node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2494e1-a746-480e-b556-10176bec0a91",
   "metadata": {},
   "source": [
    "## Selection Sort (Sorting Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584cc3b-4887-4103-bd12-e49c3a89869b",
   "metadata": {},
   "source": [
    "Suppose you have a list of n artists and you want to sort them from highest to lowest play count. You could just find the highest in the list and move it to a new list and keep on repeating. To do this, you will have to read the *n* items in the list *n* times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eea32c-8f3c-4016-ab8f-06ac77b8a1f1",
   "metadata": {},
   "source": [
    "<img src=Grokking-Algorithms-Images/3.png width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf9780-9aec-4356-9d0a-732c2fbed4ed",
   "metadata": {},
   "source": [
    "This takes O(n * n) = O(n^2) time. You might wonder why the runtime is not smaller given the fact that the list reduces in size after each read. On the first read, you read n items, then n-1 items, then n-2, all the way until 1 item remains. So, on average you read 1/2 * n items. This means that the runtime is actually O(n * 1/2 * n) but we can drop all constants so we return back to O(n^2) time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f2789-ce50-4b5a-9bd6-bbade0f61222",
   "metadata": {},
   "source": [
    "Here's a python implementation for selection sort. We need a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fba7595a-f605-4150-8a78-4005eef9987f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5, 6]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_smallest_index(arr):\n",
    "    smallest_value = arr[0]\n",
    "    smallest_index = 0\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] < smallest_value:\n",
    "            smallest_value = arr[i]\n",
    "            smallest_index = i\n",
    "    \n",
    "    return smallest_index\n",
    "\n",
    "def selection_sort(arr):\n",
    "    \n",
    "    new_arr = []\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        \n",
    "        # arr.pop(smallest_value_index) removes that value from the array and also returns it so that we can store it in our new_arr.\n",
    "        smallest_value_index = find_smallest_index(arr)\n",
    "        new_arr.append(arr.pop(smallest_value_index)) #\n",
    "                                                      \n",
    "    return new_arr\n",
    "                       \n",
    "                    \n",
    "arr = [3, 5, 6, 1, 2]\n",
    "                       \n",
    "selection_sort(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b27b7cf-ec54-4ff4-b356-4e7eff512f39",
   "metadata": {},
   "source": [
    "It's useful to think of `.pop(some_array)` as 'remove and read'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d853849-10cd-4b46-bf4a-98581f0a898c",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c9e42-1a91-423a-861b-b7647b2751b2",
   "metadata": {},
   "source": [
    "## Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88dc834-cc04-432d-aa82-3eb799c044ff",
   "metadata": {},
   "source": [
    "Recursion is when a function calls itself; all function calls go onto the call stack. A stack has two operations: push (add new item to stack) and pop (read item and remove)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7442bfc-32b1-40d6-bbfb-1ee6d458a06e",
   "metadata": {},
   "source": [
    "Stack are commonly implemented with linked lists but can be made from arrays too. Stacks are last in, first out (LIFO) data structures. They are made with a linked list by having the head be the only place for insertion and removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a3728-b7e4-42a2-af2c-0a4a656663af",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d325c006-684f-4d41-8042-b279be23e798",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quicksort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb714a9-9a24-4979-9878-25f68bd19190",
   "metadata": {},
   "source": [
    "Divide and conquer (D&C) is a general, recursive technique for solving problems. Quicksort is one of the major D&C algorithms, thus quicksort is a subset of D&C.\n",
    "\n",
    "**Let's first consider the general approach to D&C. Here's the two rules you must follow**\n",
    "\n",
    "1. Figure out a simple case as the base case.\n",
    "2. Figure out how to reduce your problem that takes you (closer) to the base case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49303f1b-7500-43d0-a578-04d01552db9c",
   "metadata": {},
   "source": [
    "<img src=Grokking-Algorithms-Images/4.png width=500 />\n",
    "\n",
    "1. What could be the base case? The easiest would be if one side was an integer multiple of the other side. That way, we can divide it evenly into N squares.\n",
    "\n",
    "2. For reducing the problem, we could mark out the biggest box that we can fit an integer amount of times. In the image below, we can only fit it twice.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/5.png width=500 />\n",
    "\n",
    "With that remaining amount of land, we could apply the exact same rule: what's the largest box that we can fit an integer amount of times?\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/6.png width=500 />\n",
    "\n",
    "We can apply this recursively until we reach the base case in which we have no remaining land after applying the algorithm. It turns out that 80m x 80m is the smallest size that fits into it. I also recognise that 80 is the greatest common divisor of 1680 and 640."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67558b-c86a-48a0-93e0-6c047b08dc87",
   "metadata": {},
   "source": [
    "Exercise: Write out the code for the earlier sum function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dab405a-3446-4faa-899c-efa79b108ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def d_and_c_sum(arr):\n",
    "    if len(arr) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return arr.pop(0) + d_and_c_sum(arr)\n",
    "    \n",
    "d_and_c_sum([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22938d09-5af4-4581-bb33-8abf67c2db05",
   "metadata": {},
   "source": [
    "Exercise: Write a recursive function to count the number of items in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7362971a-98a0-46d3-9fe8-a6118aacda14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My solution\n",
    "def count_items(some_list):\n",
    "    if some_list == []:\n",
    "        return 0\n",
    "    else:\n",
    "        some_list.pop()\n",
    "        return 1 + count_items(some_list)\n",
    "    \n",
    "\n",
    "count_items([1, 2, 3, 4, 5, 10, 12, 24, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7fed2a0e-219a-4452-8abf-d9f7f9f8ecbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Their solution\n",
    "\n",
    "def count(some_list):\n",
    "    if list == []:\n",
    "        return 0\n",
    "    return 1 + count(list[1:])\n",
    "\n",
    "count_items([1, 2, 3, 4, 5, 10, 12, 24, 35])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6612a6-e7bd-4f12-bda8-e89b43230b46",
   "metadata": {},
   "source": [
    "Exercise: Find the maximum number in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb40ded8-34ca-43f1-b605-c57d6731171f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My solution\n",
    "\n",
    "def find_max(my_list):\n",
    "    if len(my_list) == 2:\n",
    "        a = my_list[0] \n",
    "        b = my_list[1]\n",
    "        return a if a > b else b\n",
    "    \n",
    "    return my_list[0] if my_list[0] > (maximum := find_max(my_list[1:])) else maximum\n",
    "\n",
    "find_max([5, 7, 3, 9, 2, 100, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1ff22-63ac-4b8c-be46-ee927cf7a3fd",
   "metadata": {},
   "source": [
    "**Quicksort: Array with 3 or less items**\n",
    "\n",
    "Quicksort (QS) uses D&C so we first need to think of the simplest case. An array with 1 or 0 items do not need to be sorted - we can just return the array. If it has 2 items, then to order them, we can consider switching the positions of the two items (e.g. from biggest to smallest). If we have 3 or more, we're going to need a **pivot**.\n",
    "\n",
    "A **pivot** is an element of an array that we select (usually the first item). Then, we find elements smaller than the pivot and elements larger than the pivot. This is called **partitioning**.\n",
    "\n",
    "(This is similar to merge sort but this uses a pivot while merge sort just keeps on halving the subset until we reach the base case. More details are not found in this book, see elsewhere.)\n",
    "\n",
    "Here's an example with 3 elements.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/7.png width=500 />\n",
    "\n",
    "The consequence of **partitioning** is that we have:\n",
    "\n",
    "- An (unsorted) sub-array of all the numbers less than the pivot \n",
    "- The pivot \n",
    "- An (unsorted) sub-array of all the numbers greater than the pivot\n",
    "\n",
    "In the image above, QS knows how to sort an array with 2 items and an array with 0 items. If we can apply QS on both, the job would be done. This approach would work regardless of the pivot we choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac60c6-0b09-44a5-8979-05507e5165b5",
   "metadata": {},
   "source": [
    "**Quicksort: Array with 4 or more items**\n",
    "\n",
    "Firstly, we can choose 33 as the pivot. We can easily sort the RHS sub-array, but we'll need to use recursion on the LHS sub-array. It has 3 items so we need to choose a pivot for this sub array and apply QS. Now we know how to sort an array with 4 items. \n",
    "\n",
    "<img src=Grokking-Algorithms-Images/8.png width=500 />\n",
    "\n",
    "If we have an array 5 items, then depending on the pivot chosen, we can have a sub-array with a maximum length of 4 items - even if we choose the first/last element to be the pivot.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/9.png width=500 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6bf44b9f-678a-4abb-889c-6dea8950aab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "def quicksort(array):\n",
    "    if len(array) < 2:\n",
    "        return array # Base case: arrays with 0 or 1 element are already “sorted”.\n",
    "    else:\n",
    "        pivot = array[0] # Recursive case\n",
    "        less = [i for i in array[1:] if i <= pivot] # Sub-array of all the elements less than the pivot\n",
    "\n",
    "        greater = [i for i in array[1:] if i > pivot] # Sub-array of all the elements greater than the pivot\n",
    "\n",
    "        return quicksort(less) + [pivot] + quicksort(greater)\n",
    "\n",
    "print(quicksort([10, 5, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053b7e2-0cfc-4d94-ac08-cdb986c194b6",
   "metadata": {},
   "source": [
    "**Quicksort: Big O Notation**\n",
    "\n",
    "QS is unique because its speed depends on the pivot you choose. \n",
    "\n",
    "- In the worst case, QS takes O(n^2) meaning it's as slow as selection sort.\n",
    "- In the average case, QS takes O(nlogn) - this is the often quoted speed of QS.\n",
    "\n",
    "One important thing to note about Big O Notation is that just because two sorting algorithms have the same time e.g. both O(nlogn), this doesn't necessarily imply that they take the same amount of time. This is because one full iteration of one algorithm may take longer than the other.\n",
    "\n",
    "In reality, O(n) takes **c * n** where **c = some fixed amount of time that your algorithm takes.** It's called the constant. You can often neglect this constant because the functional form of big O usually dominates the constant. For example, simple search may only take 1ms per iteration while binary search may take 100 seconds, but simple search may require 1 billion iterations to complete while binary only requires 10 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e3be3-f659-4017-b77d-7ed81000c331",
   "metadata": {},
   "source": [
    "Average vs worst case:\n",
    "   \n",
    "If we choose the first element as the pivot, we require 8 recursive calls -> Worst case: **stack size** = O(n).\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/10.png width=500 />\n",
    "\n",
    "Choosing the middle element reduces this down to 4 recursive calls -> Best case: **stack size** = O(logn).\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/11.png width=500 />\n",
    "\n",
    "Each level of the call stack requires that you touch O(n) elements, no matter how you partition the array. What does vary is how many levels are in the call stack.\n",
    "\n",
    "So in the best case scenario, the number of levels in the call stack is O(logn) and each level takes O(n) time -> **O(n) * O(logn) = O(nlogn)**.\n",
    "\n",
    "In the worst case scenario, the number of levels in the call stack is O(n) and each level takes O(n) time -> **O(n) * O(n) = O(n^2)**.\n",
    "\n",
    "Unproven fact: The best case is also the average case. If you always choose a random element in the array as the pivot, quicksort will complete in O(n log n) time on average. Quicksort is one of the fastest sorting algorithms out there, and it’s a very good example of D&C.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92160d25-1ddf-4f87-9fdb-c87a73d22f59",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b391a-cbde-4191-bb14-8078f242120d",
   "metadata": {},
   "source": [
    "## Hash Tables/ Hash Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2774bea-4e66-4831-8db5-381613281c5e",
   "metadata": {},
   "source": [
    "So far, we know 2 data structures: lists and arrays. The next structure is a hash table / hash map. But first, let's cover a hash function.\n",
    "\n",
    "A **hash function maps strings to numbers**. By 'string', we refer to any kind of data - a sequence of bytes.\n",
    "\n",
    "Let's say we want a register of grocery items (keys) and their prices (values). \n",
    "\n",
    "1. We start with an empty array with, say, 5 indices available (0 - 4)\n",
    "2. We pass in the string 'Apple' to the hash function.\n",
    "3. The hash function returns the index 3.\n",
    "4. We store the price of an apple at this index.\n",
    "\n",
    "We repeat this process until all grocery items are added to the array.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/12.png width=500 />\n",
    "\n",
    "Now, whenever we want to find the price of an apple, we don't search the array. Instead, we feed 'Apple' to the hash function and it tells us the index 3 and we search that index to find the price. This computes in O(1) time always. Also, the hash function knows the size of the array so it will only return a valid index.\n",
    "\n",
    "In summary,  you can use it the first time to find where to store the price of an apple, and then you can use it to find where you stored that price.\n",
    "\n",
    "**Hash function + Array = Hash Table**\n",
    "\n",
    "While lists and arrays map straight to memory, the hash table data structure has some hidden logic behind it which helps it figure out how to do it intelligently.\n",
    "\n",
    "They’re also known as hash maps, maps, dictionaries, and associative arrays. And hash tables are fast! Remember our discussion of arrays and linked lists back in chapter 2? You can get an item from an array instantly (reading arrays takes O(1) time). And hash tables use an array to store the data, so they’re equally fast.\n",
    "\n",
    "We know how to implement them in Python. Simply using `dict` or `{}`.\n",
    "\n",
    "Hash tables are great when you want to:\n",
    "- Create a mapping from one thing to another thing\n",
    "- Look something up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2ced4-d15f-426d-8045-69424d391bb9",
   "metadata": {},
   "source": [
    "Checking for duplicates is convenient using hash tables too. We can use the property `.get` to see if a particular string has been added to the hash table. If it hasn't, `.get` returns `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0a0f949-048b-40c8-8dfa-52fa342287ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "voters_list = {}\n",
    "\n",
    "voters_list['Jim'] = True\n",
    "\n",
    "print(voters_list.get('Jim'))\n",
    "print(voters_list.get('Pam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a45257-9021-429a-baa5-cf336274d076",
   "metadata": {},
   "source": [
    "**Using hash tables as a cache**\n",
    "\n",
    "Instead of a website doing work every single time you make a request to the website's server, it can just cache (using hash maps) the most commonly used web pages. For example, the About Page, Contact Page, Home Page etc. So, when you make a request, it first checks to see if that url e.g. facebook.com/About is in the hash table. If not, then the server does some work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a28af-eca2-4d59-a733-40406bde62b2",
   "metadata": {},
   "source": [
    "To recap, hashes are good for: \n",
    "- Modeling relationships from one thing to another thing\n",
    "- Filtering out duplicates\n",
    "- Caching/memorizing data instead of making your server do work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95155e3-4c5c-4bde-97f8-6b27506a4089",
   "metadata": {},
   "source": [
    "## Collisions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e1b67-7b98-49a9-a95a-9e2dc31c1dc3",
   "metadata": {},
   "source": [
    "In reality, it's almost impossible to map different keys to different values. If we have a simple hash function that maps strings to an index based on alphabetical order, and we have a small array, we may get two keys assigned to the same value. This is known as a **collision**. For example, we assign the price of 'Apples' which takes index 0, the price of 'Bananas' which takes index 1, but then we try to assign the price of 'Avocados'. Both the 'Apples' and 'Avocados' keys will point to the same index 0. \n",
    "\n",
    "One solution is to start a linked list: \n",
    "\n",
    "<img src=Grokking-Algorithms-Images/13.png width=500 />\n",
    "\n",
    "If this linked list is small, it won't take much time to search through the words beginning with 'A', especially if you've got a good hash function. Ideally, our hash function would map keys evenly over the hash."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de4995-f019-4d21-8a65-3e247be808ed",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a49e5-6d25-41ba-820a-0501fb74e881",
   "metadata": {},
   "source": [
    "This is the performance table of a hash map. In the average case it takes O(1) which means constant time. This means that it takes the same amount of time regardless of how large the hash table is.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/14.png width=500 />\n",
    "\n",
    "The worst case is reached if you constantly experience collisions. There are two things needed to avoid collisions:\n",
    "\n",
    "- A low load factor\n",
    "- A good hash function\n",
    "\n",
    "(The following information isn't necessary - it's a peak under the hood. You won't be implementing hash tables from scratch, but I'll write a quick summary.)\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/15.png width=500 />\n",
    "\n",
    "If the load factor increases past 0.7, you'll create a new array generally double the size of the old array and insert all the old items into the new array.\n",
    "\n",
    "A good hash function that's typically used is SHA (secure hash algorithm). Normally, we've seen hash functions take a string and convert to an array index. SHA however, takes a string and converts it into another string.\n",
    "\n",
    "This is useful for checking passwords. When you type in your password, Google, for example, hashes it and checks it against the hash in its database. If Google gets hacked, they only have access to the hashed password. Since SHA is one-way, then cannot retrieve the original password."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97011c99-966c-4ff4-be54-0be2276e9858",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e348b-0cee-4a94-900c-1962be89f510",
   "metadata": {},
   "source": [
    "## Breadth-first search (BFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9770b7-f77a-4fec-b6c0-5a449aff3eb1",
   "metadata": {},
   "source": [
    "The algorithm to solve a shortest-path problem is called breadth-first search. This short path could be the smallest number of mobes to checkmate in a game of chess.\n",
    "\n",
    "BFS generally helps answer two types of questions:\n",
    "\n",
    "1. Is there a path from node A to node B?\n",
    "2. What is the shortest path from node A to node B?\n",
    "\n",
    "An example of number 1 could be seeing if you can find someone who sells mangoes. First you see if any of your friends sells mangoes and if not, you see if any of their friends sells mangoes, and so on. This is still a BFS algorithm.\n",
    "\n",
    "An example of number 2 could be trying to find the closest mango seller. Intuitively, we should search all first-degree connections before radiating outwards (i.e. 'breadth') to friends of friends (2nd degree). The corollary of this approach is that it answers both questions 1 and 2.\n",
    "\n",
    "One important thing is order; when checking our 1st degree contacts, it's important that we add the 2nd degree contacts to the search list **after** all the 1st degree contacts have been searched. Otherwise, we won't get an optimal solution. There's a data structure that deals with this called a **queue**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10da91-ae5a-47ef-b839-9ab491ca3fd9",
   "metadata": {},
   "source": [
    "## Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a71565-0d7c-4688-8ada-b31773775d3c",
   "metadata": {},
   "source": [
    "Queues are similar to stacks. You can’t access random elements in the queue. Instead, there are two only operations, enqueue and dequeue.\n",
    "\n",
    "- Enqueue: Add an item to a queue. aka `push`\n",
    "- Dequeue: Take an item off a queue. `pop`\n",
    "\n",
    "\n",
    "\n",
    "Queues can be implemented with a linked list or an array that only removes from the head and adds to the tail. This is in contrast to a stack which is also made with a linked list but you can only perform insertion and removal on the head.\n",
    "\n",
    "The queue data structure is called a FIFO data structure: First In, First Out. In contrast, a stack is a LIFO data structure: Last in, First Out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a12c8-cb8d-4665-8d1b-8cf7589d48f2",
   "metadata": {},
   "source": [
    "## Code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ac356-83ad-43ee-9ff7-1683225da948",
   "metadata": {},
   "source": [
    "How do we express a node connection in code, i.e. an A -> B mapping. We've seen this structure before: **Hash tables**. Since it's one-way, we call this a **directed graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92b2fc23-db74-4824-a2df-9783220039bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {}\n",
    "graph[\"you\"] = [\"alice\", \"bob\", \"claire\", \"Phillip\"]\n",
    "graph[\"alice\"] = [\"peggy\", \"zack\", \"Chip\"]\n",
    "graph[\"bob\"] = [] # No contacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac8384-fdbb-4bf0-9226-2ea04f0f6216",
   "metadata": {},
   "source": [
    "Here's the implmentation of the queue:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/16.png width=500 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9873feae-0568-4442-90d7-95a3909ce849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking to see if alice is a mango seller\n",
      "Nope!\n",
      "Checking to see if bob is a mango seller\n",
      "Nope!\n",
      "Checking to see if claire is a mango seller\n",
      "Nope!\n",
      "Checking to see if phillip is a mango seller\n",
      "phillip is a mango seller; we can return here to quit our function if we like.\n",
      "\n",
      "Checking to see if contact of alice: zack is a mango seller\n",
      "Nope!\n",
      "Checking to see if contact of alice: chip is a mango seller\n",
      "contact of alice: chip is a mango seller; we can return here to quit our function if we like.\n",
      "\n",
      "Checking to see if contact of bob: john is a mango seller\n",
      "Nope!\n",
      "Checking to see if contact of bob: tripp is a mango seller\n",
      "contact of bob: tripp is a mango seller; we can return here to quit our function if we like.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "graph = {}\n",
    "\n",
    "# 1st degree\n",
    "graph[\"you\"] = [\"alice\", \"bob\", \"claire\", \"phillip\"]  \n",
    "\n",
    "# 2nd degree\n",
    "graph[\"alice\"] = [\"contact of alice: zack\", \"contact of alice: chip\"]\n",
    "graph[\"bob\"] = [\"contact of bob: john\", \"contact of bob: tripp\"] # No contacts\n",
    "graph[\"claire\"] = [] # No contacts\n",
    "graph[\"phillip\"] = [] # No contacts\n",
    "\n",
    "# 3rd degree\n",
    "\n",
    "graph['zack'] = []\n",
    "graph['chip'] = []\n",
    "\n",
    "# graph['john'] = []\n",
    "# graph['tripp'] = []\n",
    "\n",
    "\n",
    "\n",
    "def person_is_seller(name):\n",
    "    return name[-1] == 'p' # arbitrary rule for demonstration purposes.\n",
    "\n",
    "def bfs():\n",
    "    \n",
    "    search_queue = deque() # creates a new queue\n",
    "    search_queue += graph[\"you\"] # the RHS simply returns all your neigbours to the search queue. So, we add them to the search queue.\n",
    "    searched = [] # if two people have a mutual friend, we don't want to add them twice to our queue so we create a list of all those searched.\n",
    "    \n",
    "    while search_queue:\n",
    "    \n",
    "        # grab the first person off the queue.\n",
    "        # popleft() is a property of deque which is faster than doing .pop(0).\n",
    "        person = search_queue.popleft() \n",
    "        print(f'Checking to see if {person} is a mango seller')\n",
    "        \n",
    "        if person not in searched:\n",
    "    \n",
    "            if person_is_seller(person):\n",
    "                print(f'{person} is a mango seller; we can return here to quit our function if we like.\\n')\n",
    "    \n",
    "            else:\n",
    "                print('Nope!')\n",
    "            \n",
    "                # if they're not, add all of this person's friends to our queue.\n",
    "                # if this person has no friends, 'get' would return None, but you can't add 'None' to a list via concatenation.\n",
    "                # So, we setup a default return of `[]`. This can be concantenated to the search_queue list.\n",
    "                search_queue += graph.get(person, []) \n",
    "\n",
    "\n",
    "bfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2eb75-448a-4a0c-880e-0fa47f86d28a",
   "metadata": {},
   "source": [
    "Quick note about above code: \n",
    "\n",
    "John and Trip are 3rd degree contacts without any contacts for themselves, but we can't enqueue 'nothing' or 'None' to our list.\\\n",
    "Strictly, we could add an empty list to their list of contacts: `graph['john'] = []`, but we can bypass this issue by adding a default return of `[]` to `.get`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1366c087-b25f-44de-835b-44e257028ef7",
   "metadata": {},
   "source": [
    "The runtime of searching using BFS will be at least O(n) where n is the number of connections. But we also need to perform inserts into a queue. Since it takes O(1) to add a single person to our queue, it will take O(number of people) to add everyone to our queue. \n",
    "\n",
    "In total we have O(V+E) where V is the number of vertices (people) and E is the number of edges (connections)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eba6c44-d631-4271-b91f-23d6882464c5",
   "metadata": {},
   "source": [
    "Asides:\n",
    "\n",
    "- For graphs, if our connections represent dependencies e.g. Exercise <- shower <- get dressed, then this is called a **topological sort**.\n",
    "\n",
    "- A **tree** is a special type of graph where no edges ever point up to a higher node, therefore, trees contain no loops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b13f1-4d82-4d4b-98cc-381b6ae95c75",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421257f-33ec-414c-922b-826e4766c413",
   "metadata": {},
   "source": [
    "## Dijkstra's Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492bb66e-dbcc-44f0-b14f-aa1f6d67bb3d",
   "metadata": {},
   "source": [
    "There are 4 steps to Dijkstra's algorithm:\n",
    "\n",
    "1. Find the “cheapest” node. This is the node you can get to in the least amount of time.\n",
    "2. Update the costs of the neighbors of this node.\n",
    "3. Repeat until you’ve done this for every node in the graph.\n",
    "4. Calculate the final path.\n",
    "\n",
    "Step 1: Find the cheapest node. In this case, it's node B.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/17.png width=200 />\n",
    "\n",
    "Step 2: Calculate how long it takes to get to each of node B's neighbours **by going through B**. We see that it only takes 5 minutes to get to A and 7 minutes to get to the finish. **This is an important step; we are essentially trying to find a cheaper way to reach that particular node, thereby obsoleting all other ways.**\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/18.png width=400 />\n",
    "\n",
    "Step 3: Update the costs so write somewhere that 'A' takes 5 minutes (instead of 6) and finish takes 7 (instead of infinity).\n",
    "\n",
    "Now, repeat this entire process for the next chepeast node.\n",
    "\n",
    "Step 4 (step 1 repeated):  Now A is the next cheapest node.\n",
    "\n",
    "Step 5 (step 2 repeated): A's only neighbour is the finish line .\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/19.png width=300 />\n",
    "\n",
    "Step 6 (step 3 repeated): Update costs for finish line from 7 to 6.\n",
    "\n",
    "Note that we repeat this for every node except the final (finish) node. This is **not** BFS because BFS can only be used on unweighted graphs - it only considers the number of nodes. Also note that Dijkstra only works on directed acyclic graphs (DAGs). This means that there cannot be any loops or double-sided arrows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1423324c-da3d-4c48-ad51-5fac65eb1e66",
   "metadata": {},
   "source": [
    "There's another example in the full notes in which you're trying to trade a book to get a piano for the least amount.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/20.png width=500 />\n",
    "\n",
    "It's useful to add the 'parent' column so that you know how you got that low cost value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f173e-8747-4758-8060-0ca67a7f6879",
   "metadata": {},
   "source": [
    "Note that Dijkstra's algorithm breaks if you have negative weights. The solution for a negative-weighted graph is another algorithm called **Bellman-Ford algorithm**, but it's out the scope of this book/summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661c678-5f5c-4af1-9f17-dc25db6e04ac",
   "metadata": {},
   "source": [
    "## Dijkstra's Algorithm - Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05036e47-148d-4d8c-8b51-74d1ada36d2e",
   "metadata": {},
   "source": [
    "To implement this in code, we'll need 3 hashmaps. One for all the pairings in the graph (that won't be mutated), one for the costs (that will be updated) and one for the parents (that is also updated).\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/21.png width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785f1bc-1bdf-4627-a8a7-6e05ae455f9b",
   "metadata": {},
   "source": [
    "For the graph hashmap, we can represent the weights to **A** and **B** like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a130b62-959f-42a7-9de9-a10200ab589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': {'a': 6, 'b': 2}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = {}\n",
    "\n",
    "graph['start'] = {}\n",
    "graph['start']['a'] = 6\n",
    "graph['start']['b'] = 2\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a91ec0-e125-4516-88d2-dda5ff396ff1",
   "metadata": {},
   "source": [
    "Now the remaining nodes. The diagram version is:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/22.png width=250 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef3b9f39-d1b2-41dd-b7b6-b6d5e44540b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['a'] = {}\n",
    "graph['a']['finish'] = 1\n",
    "\n",
    "graph['b'] = {}\n",
    "graph['b']['finish'] = 5\n",
    "graph['b']['a'] = 3\n",
    "\n",
    "graph['finish'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a1ad2-0597-44f5-8d3d-d5a2820d3caa",
   "metadata": {},
   "source": [
    "The cost of a node is how long it takes to get to that node from the start. Here’s the code to make the costs table:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/23.png width=250 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e83130f-4ae6-48c5-b10d-719d810a00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "infinity = float('inf') #this creates the actual python-recognised infinity value\n",
    "\n",
    "costs = {}\n",
    "costs['a'] = 6\n",
    "costs['b'] = 2\n",
    "costs['finish'] = infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363c876-97e3-4917-8d4f-e512738d35ef",
   "metadata": {},
   "source": [
    "Finally, the parents hashtable.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/24.png width=250 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93fdcceb-bf6e-435e-8089-72043819e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = {}\n",
    "parents['a'] = 'start'\n",
    "parents['b'] = 'start'\n",
    "parents['finish'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26684e65-4458-4020-a52f-a6ca90030ea7",
   "metadata": {},
   "source": [
    "Finally, you need an array to keep track of all the nodes you’ve already processed, because you don’t need to process a node more than once. We choose an array because we can iterate through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9be030ef-f298-4770-a5e9-5b505f884161",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24a36f-4ba9-4ae2-9ff0-8079c80d547e",
   "metadata": {},
   "source": [
    "<img src=Grokking-Algorithms-Images/25.png width=350 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38ef41f5-da79-4941-b836-786b64bc6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lowest_cost_node(costs):\n",
    "    lowest_cost = float('inf')\n",
    "    lowest_cost_node = None\n",
    "    \n",
    "    for node in costs: # Go through each node.\n",
    "        cost = costs[node]\n",
    "        \n",
    "        if cost < lowest_cost and node not in processed:\n",
    "            lowest_cost = cost # … set it as the new lowest-cost node.\n",
    "            lowest_cost_node = node\n",
    "            \n",
    "    return lowest_cost_node\n",
    "\n",
    "node = find_lowest_cost_node(costs) # Find the lowest-cost node that you haven’t processed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d3142fa-d8f0-4de9-9472-68ce6c82c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "while node is not None: # If you’ve processed all the nodes, this while loop is done.\n",
    "    cost = costs[node] \n",
    "    neighbors = graph[node]\n",
    "     \n",
    "    for n in neighbors.keys(): # Go through all the neighbors of this node.\n",
    "        new_cost = cost + neighbors[n] # If it’s cheaper to get to this neighbor \n",
    "        \n",
    "        if costs[n] > new_cost: # by going through this node …\n",
    "            costs[n] = new_cost # … update the cost for this node.\n",
    "            parents[n] = node # This node becomes the new parent for this neighbor\n",
    "         \n",
    "    processed.append(node) # Mark the node as processed.\n",
    "    node = find_lowest_cost_node(costs) # Find the next node to process, and loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b65f1861-3cf5-4fce-ac09-7c02d5528c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 5, 'b': 2, 'finish': 6}\n",
      "{'a': 'b', 'b': 'start', 'finish': 'a'}\n"
     ]
    }
   ],
   "source": [
    "print(costs) # the cost to finish is only 6.\n",
    "print(parents) # this is the path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a797dc-0fd5-4ae9-898a-48661a94b3fc",
   "metadata": {},
   "source": [
    "As you can see, 'finish's parent is 'a', 'a's parent is 'b' and 'b's parent is 'start'. So, 'start' > 'b' > 'a' > 'finish'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17296780-27e0-4484-b3ff-679421840d69",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ac5cf-cd2e-4c66-8392-db5466afa535",
   "metadata": {},
   "source": [
    "## Greedy Algorithms/Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1887a-f537-40da-9f7a-c132345aba94",
   "metadata": {},
   "source": [
    "Here you'll tackle the problems that have no fast algorithmic solution (NP-complete problems), and how to identify such problems.\n",
    "\n",
    "Imagine you have a list of choices for the classes you can take at a school. You want to take as many classes as possible but since some of them overlap, you won't be able to take them all. We can use the greedy algorithm: \n",
    "\n",
    "A greedy algorithm is simple: at each step, pick the optimal move. In this case, each time you pick a class, you pick the class that ends the soonest. In technical terms: at each step you pick the locally optimal solution. Then, you pick the next class that starts after the first class but ends the soonest. Keep on repeating and in the end you’re left with the globally optimal solution. Believe it or not, this simple algorithm finds the optimal solution to this scheduling problem!\n",
    "\n",
    "These algorithms don't always work.\n",
    "\n",
    "Here's another example: If you're a thief with a 20kg bag in a shop with items of various values - in what order do you take the items? \n",
    "The solution is the intuitive one: Take the most expensive thing without worrying about its weight (locally optimal), then take the next most expensive item. Keep going until you run out of space. \n",
    "\n",
    "You certainly won't get the most optimal solution but it works *pretty well* and is easy to code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d5963c-d3a2-451e-9940-bd2f7cc4f2ac",
   "metadata": {},
   "source": [
    "## Set-covering problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae9a9f-3fc3-4a0e-a2a1-bd52e4bd07b0",
   "metadata": {},
   "source": [
    "This is a scenario where the greedy strategy is absolutely necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64192dc4-b7f3-410d-be0a-590d8e4c5c4a",
   "metadata": {},
   "source": [
    "Suppose you’re starting a radio show. You want to reach listeners in all 50 states. You have to decide what stations to play on to reach all those listeners. It costs money to be on each station, so you’re trying to minimize the number of stations you play on. You have a list of stations.\n",
    "\n",
    "Each station covers a region, and there’s overlap. How do you figure out the smallest set of stations you can play on to cover all 50 states? Sounds easy, doesn’t it? Turns out it’s extremely hard. Here’s how to do it:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/26.png width=200 /> <img src=Grokking-Algorithms-Images/27.png width=200 />\n",
    "\n",
    "1. List every possible subset of stations. There are 2^n possible subsets. \n",
    "\n",
    "If you have 3 stations, you have 8 subsets:\\\n",
    "{},\\\n",
    "{A}, {B}, {C},\\\n",
    "{AB}, {AC}, {BC},\\\n",
    "{ABC}\n",
    "\n",
    "This is called the **power set** and the power set of x = {ABC} is the set of all subsets of x including x itself and the empty set. Putting all above subsets into one big set is called the power set of {ABC}.\n",
    "\n",
    "2. Now from all these subsets, pcik the set with the smallest number of stations that covers all 50 states.\n",
    "\n",
    "That's it, but because  2^n stations, it takes O(2^n) time which is very slow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315955f8-6806-4283-b9dc-c56e5feedd8a",
   "metadata": {},
   "source": [
    "Now with the greedy approach:\n",
    "\n",
    "1. Start with all states uncovered. Pick the station that covers the most states. \n",
    "2. Repeat until all the states are covered. It’s OK if a station covers some states that have been covered already.\n",
    "\n",
    "This is an approximation algorithm. It runs in O(n^2) as opposed to O(2^n) where n is the number of radio stations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ecde0f-c0e6-492f-948f-95c556a41117",
   "metadata": {},
   "source": [
    "Now in code. Note that we use a set so that we don't have repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e14a528-27e2-4e74-b442-af624f97961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_needed = set(['mt', 'wa', 'or', 'id', 'nv', 'ut', 'ca', 'az'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf78f73-56b7-4723-ad99-def9d701c7fe",
   "metadata": {},
   "source": [
    "Now we can use a hash set to map each radio station to the states that it covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49328c25-2565-43bd-8b33-4237ecd3103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = {}\n",
    "stations['kone'] = set(['id', 'nv', 'ut'])\n",
    "stations['ktwo'] = set(['wa', 'id', 'mt'])\n",
    "stations['kthree'] = set(['or', 'nv', 'ca'])\n",
    "stations['kfour'] = set(['nv', 'ut'])\n",
    "stations['kfive'] = set(['ca', 'az'])\n",
    "\n",
    "final_stations = set() # To hold the answer of the final set of stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb208f94-9b77-41d9-a3c1-29f66997c45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kone\n"
     ]
    }
   ],
   "source": [
    "best_station = None\n",
    "states_covered = set() # a set of all the states this station covers that haven’t been covered yet\n",
    "\n",
    "for station, states_covered_by_station in stations.items(): # loop over all stations to see which is the best station.\n",
    "\n",
    "    covered = states_needed & states_covered_by_station # & is the intersection of these two sets.\n",
    "    \n",
    "    if len(covered) > len(states_covered): # if the size of the set for this particular station in the loop is greater than the size of the best station.. \n",
    "        best_station = station # update.\n",
    "        states_covered = covered\n",
    "        \n",
    "final_stations.add(best_station) \n",
    "print(best_station) # We've found the state that covers the most states. Now we've got to remove these states from states_needed and run the loop again.\n",
    "\n",
    "states_needed = states_needed - states_covered "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dd01e-2181-4337-88a9-7a2bcc8f24fd",
   "metadata": {},
   "source": [
    "The last line is a *set difference*. If A = {1, 2, 3} and B = {3, 5}, then A - B = {1, 2}. It is the same as 'A and not B'.  \n",
    "\n",
    "Now we'll present the full code for this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab9592ba-3c79-470b-a4ec-5202994c909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kone', 'kfive', 'kthree', 'ktwo'}\n"
     ]
    }
   ],
   "source": [
    "states_needed = set(['mt', 'wa', 'or', 'id', 'nv', 'ut', 'ca', 'az'])\n",
    "\n",
    "stations = {}\n",
    "stations['kone'] = set(['id', 'nv', 'ut'])\n",
    "stations['ktwo'] = set(['wa', 'id', 'mt'])\n",
    "stations['kthree'] = set(['or', 'nv', 'ca'])\n",
    "stations['kfour'] = set(['nv', 'ut'])\n",
    "stations['kfive'] = set(['ca', 'az'])\n",
    "\n",
    "final_stations = set() # we cannot use final_stations = {} because Python creates a dictionary, not a set. And dictionaries don't have '.add' methods.\n",
    "\n",
    "while states_needed:\n",
    "    best_station = None\n",
    "    states_covered = set()\n",
    "    \n",
    "    for station, states in stations.items():\n",
    "        covered = states_needed & states\n",
    "        \n",
    "        if len(covered) > len(states_covered):\n",
    "            best_station = station\n",
    "            states_covered = covered\n",
    "            \n",
    "    states_needed -= states_covered\n",
    "    final_stations.add(best_station)\n",
    "\n",
    "print(final_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c5f2e-f65a-4878-a9d9-663494358c15",
   "metadata": {},
   "source": [
    "Quicksort is *not* a greedy algorithm but breadth-first search (BFS) and Dijkstra's Algorithm *are* greedy algorihthms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09844da9-2c24-4279-b5d6-f6d076d664e3",
   "metadata": {},
   "source": [
    "## NP Complete problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39f2bf6-cb7b-4720-9b0b-c447b7269de1",
   "metadata": {},
   "source": [
    "**Travelling Salesman**\n",
    "\n",
    "Consider the possible routes for a salesman going to a number of cities. Assume all routes are directed i.e. going A -> B is a different route to going B -> A, and also assume that you can start at any one of the cities. This is the factorial function. \n",
    "\n",
    "<img src=Grokking-Algorithms-Images/28.png width=500 />\n",
    "\n",
    "This problem and the set-covering problem both have something in common: you must calculate every possible solution and pick the smallest one. Both of these problems are NP-complete (non-deterministic polynomial-time complete)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a429867-f3dd-450e-a84d-933f463201af",
   "metadata": {},
   "source": [
    "**How do you tell if a problem is NP-complete?**\n",
    "\n",
    "Here are some giveaways:\n",
    "\n",
    "- Your algorithm runs quickly with a handful of items but really slows down with more items.\n",
    "- “All combinations of X” usually point to an NP-complete problem.\n",
    "- Do you have to calculate “every possible version” of X because you can’t break it down into smaller sub-problems? Might be NP-complete.\n",
    "- If your problem involves a sequence (such as a sequence of cities, like traveling salesperson), and it’s hard to solve, it might be NP-complete.\n",
    "- If your problem involves a set (like a set of radio stations) and it’s hard to solve, it might be NP-complete.\n",
    "- Can you restate your problem as the set-covering problem or the traveling-salesperson problem? Then your problem is definitely NP-complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdb61e-c754-41d5-b15e-e78087213847",
   "metadata": {},
   "source": [
    "**Recap**\n",
    "\n",
    "- Greedy algorithms optimize locally, hoping to end up with a global optimum.\n",
    "- NP-complete problems have no known fast solution.\n",
    "- If you have an NP-complete problem, your best bet is to use an approximation algorithm.\n",
    "- Greedy algorithms are easy to write and fast to run, so they make good approximation algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a66d9f6-6c06-4e36-bf42-426161bd20f5",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 9 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f8912-756d-48ce-8432-a2c50f36cd62",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ea56d-246a-4bef-bd24-cba68b4b4b95",
   "metadata": {},
   "source": [
    "### Knapsack Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300c180-3ddc-4894-ba75-bec225743fbc",
   "metadata": {},
   "source": [
    "This is a technique to solve a hard problem by breaking it up into subproblems and solving those subproblems first. Unlike greedy algorithms, it will find the optimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004409f-cf40-4ec5-b4ea-221f1e75e5ae",
   "metadata": {},
   "source": [
    "Let's say we have a knapsack that can carry 4lb of goods\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/29.png width=400 />\n",
    "\n",
    "We're trying to maximise the value of the knapsack. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795f5a9-f16d-4f29-9060-3fb29cda3600",
   "metadata": {},
   "source": [
    "In dynamic programming, we try to solve the problem for sub-knapsacks and then work up to solving the original problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5a5e9-b401-4d69-a8e6-a8670ce5acf2",
   "metadata": {},
   "source": [
    "<img src=Grokking-Algorithms-Images/30.png width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254a232-674c-4684-b3b0-669dc3eeff89",
   "metadata": {},
   "source": [
    "Above is a grid that we can create to visualise the problem. I'll explain it via this grid and then how we can calculate each value in the grid using one formula only.\n",
    "\n",
    "- Each i'th row represents the item of value and each j'th column represents the size of the knapsack in lb. \n",
    "- We start by filling in each row from left to right and then top to bottom, eventually reaching the original problem in the bottom right corner.\n",
    "- Thus, each row represents the current best guess for this maximum, e.g. row 3 is *always* more up-to-date than row 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535ae48-b59b-467d-a51c-796c499bf8dd",
   "metadata": {},
   "source": [
    "Approach:\n",
    "\n",
    "1. Starting with the guitar row (i = 1), we ask ourselves, what is the most amount of value we can fit in 1 lb (j = 1) with a choice from the list: [guitar]?\n",
    "2. Of course, since the guitar is the only choice we have and it fits in all knapsacks ranging from 1 - 4 lb, we write the value and the item in each box.\n",
    "3. On the stereo row (i = 2), what is the most amount of value we can fit in 1 lb (j = 1) with a choice from the list: [stereo, guitar]?\n",
    "4. Since the stereo weighs 4 lb, we can only consider it for knapsacks that can carry 4 lb or more. In sub-knapsacks weighing less, we default to the guitar row solution.\n",
    "5. At (stereo, 4lb) i.e. (i=2, j=4), we ask ourselves, is the value in the row *directly* above higher than the value of the stereo? Since the stereo is \\\\$3000, we choose it.\n",
    "6. For the final row (i = 3), what is the most amount of value we can fit in 1 lb (j = 1) with a choice from the list: [laptop, stereo, guitar]?\n",
    "7. Since the laptop and stereo weigh 3 lb or more, the first two columns must use the default value of the column directly above.\n",
    "8. For (i=3, j=3), we need to make another value comparison: is \\\\$1500 from the *directly* above column higher than the value of the item of the current row, i.e., the laptop?\n",
    "9. The laptop has a higher value of \\\\$2000 so we choose it.\n",
    "10. For the final cell (i=3, j=4), we make the same comparison: is the previous value in the *directly above* column higher than the value of the current row's item, i.e., the laptop?\n",
    "11. The laptop doesn't cost more than the stereo (\\\\$3000 vs \\\\$2000), but the laptop leaves 1 lb of free space which has an associated value. We can determine that value right from our value table.\n",
    "12. Go to the last *completed* row and find the value associated with the remaining space. It is 1 lb so go to column 1 and read off the \\\\$1500 value.\n",
    "13. To state the final comparison: \\\\$3000 stereo from the row above, or, \\\\$3500 from the value of current row's item + value of remaining 1 lb?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1534dd-34fa-454b-9be7-88aeab5ad234",
   "metadata": {},
   "source": [
    "This entire approach can be substituted by the formula:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/31.png width=600 />\n",
    "\n",
    "Note that where it says 'value of the remaining space' is equivalent to cell: [ i - 1 ][ j - item's weight ], it means, taking i=3 and j=4 and item's weight being 3 lb as an example, we get [ 3 - 1 ][ 4 (lb) - 3 (lb) ] = [2, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245c8c1-e25b-4d4c-a3d9-14c771901205",
   "metadata": {},
   "source": [
    "Final notes: \n",
    "- You can change the order of the rows, but only the order of the iterations will change and hence, the final answer will remain the same.\n",
    "- You shouldn't fill in the grid column-wise - it may work sometimes like for this knapsack problem, but not always.\n",
    "- If you are given information of a new item that you can steal, you simply add a row below the final and work through it. You don't have to recalculate everything. This is the power of dynamic programming.\n",
    "- What if you add an item of a smaller weight e.g. 0.5 lb? Since our table only accounts for integer lbs, we must add in extra columns at 0.5, 1.5, 2.5, 3.5 lbs etc. to account for the finer granularity.\n",
    "- You can't account for fractions of items, e.g. x amount of gold for x amount of value, using dynamic programming. But you can use a greedy algorithm instead to get a fast non-optimal solution. Simply take as much as you can of the most valuable item.\n",
    "- Dynamic programming only works when each subproblem is discrete — when it doesn’t depend on other subproblems. So for example, if you had an itinerary to go to France which takes 1 day to go there and see the sights, each of which take 0.5 days, then each activity takes 1.5 days. You can't consider the fact that once you're in paris, you no longer need to consider the 1 day travel to paris for each activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b625239-db38-42b4-97c9-f304d1d29a02",
   "metadata": {},
   "source": [
    "### Travel Itinerary Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368c61bb-b01f-4d33-bc1f-e374758570fd",
   "metadata": {},
   "source": [
    "Firstly, it can be useful to generalise the concepts a little knowing what we now know. From the last example, we saw items and their values. It can be useful to think of the items as 'costs' and the prices of those items as 'values'. In this example, we will suppose that you’re going to London for a nice vacation. You have two days there and a lot of things you want to do. You can’t do everything, so you make a list.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/32.png width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f8302f-9c2e-4137-85da-84f1e1a45daa",
   "metadata": {},
   "source": [
    "Here's the solution:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/33.png width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d749664-8d48-4be9-934a-71ecfa462a2d",
   "metadata": {},
   "source": [
    "### Longest common substring problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a8f84-c553-4035-9c22-89afd6632d50",
   "metadata": {},
   "source": [
    "Suppose you run dictionary.com. Someone types in a word, and you give them the definition. But if someone misspells a word, you want to be able to guess what word they meant. Alex is searching for fish, but he accidentally put in hish. That’s not a word in your dictionary, but you have a list of words that are similar.\n",
    "\n",
    "Similar to 'hish':\n",
    "- fish \n",
    "- vista\n",
    "\n",
    "There isn't a systematic way to figure out the axes, values, and costs of the grid. But using what we know, we can start experimenting:\n",
    "\n",
    "- First, we could compare 'hish' to 'fish' and find the longest common substring. Then, repeate for 'hish' and 'vista'.\n",
    "- Create grids for each and see which one contains the highest value.\n",
    "\n",
    "Because we know the final answer, we can just fill in the grid and then generalise/ determine the rules after.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/34.png width=250 />\n",
    "\n",
    "And here's the formula annotated: \n",
    "\n",
    "<img src=Grokking-Algorithms-Images/35.png width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84891fea-222c-4fbb-920a-69e290926792",
   "metadata": {},
   "source": [
    "Here's the grid for 'hish' and 'vista':\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/36.png width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47559705-1a22-43bd-80ce-8d5dbe206074",
   "metadata": {},
   "source": [
    "We can see issues with this approach. If we instead typed 'fosh' and we had to pick out of 'fish' and 'fort', this approach values both options as 2, but clearly 'fish' is closer to 'fosh'. So, we need the *longest common subsequence* instead of *longest common substring*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118afd3a-9ac4-4b2f-b59e-80c8529d22a1",
   "metadata": {},
   "source": [
    "<img src=Grokking-Algorithms-Images/37.png width=300 />\n",
    "\n",
    "By 'pick the larger', they mean compare with the cell directly to the left and the cell directly above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27977c-96bc-4856-9b3f-13d3d5a89374",
   "metadata": {},
   "source": [
    "Takeaways and tips:\n",
    "\n",
    "- Dynamic programming is useful when you’re trying to optimizesomething given a constraint. In the knapsack problem, you had to maximize the value of the goods you stole, constrained by the size of the knapsack. Dynamic programming is useful when you’re trying to optimize something given a constraint. In the knapsack problem, you had to maximize the value of the goods you stole, constrained by the size of the knapsack. \n",
    "\n",
    "- You can use dynamic programming when the problem can be broken into discrete subproblems, and they don’t depend on each other.\n",
    "\n",
    "- Every dynamic-programming solution involves a grid.\n",
    "\n",
    "- The values in the cells are usually what you’re trying to optimize. For the knapsack problem, the values were the value of the goods.\n",
    "\n",
    "- Each cell is a subproblem, so think about how you can divide your problem into subproblems. That will help you figure out what the axes are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8795948-2711-44d6-a86b-029958b98e9d",
   "metadata": {},
   "source": [
    "Dynamic programming is used in a bunch of scenarios:\n",
    "\n",
    "- Biologists use the longest common subsequence to find similarities in DNA strands. They can use this to tell how similar two animals or two diseases are. The longest common subsequence is being used to find a cure for multiple sclerosis.\n",
    "\n",
    "- Have you ever used diff (like git diff)? Diff tells you the differences between two files, and it uses dynamic programming to do so.\n",
    "\n",
    "- We talked about string similarity. Levenshtein distance measures how similar two strings are, and it uses dynamic programming. Levenshtein distance is used for everything from spell-check to figuring out whether a user is uploading copyrighted data. \n",
    "\n",
    "- Have you ever used an app that does word wrap, like Microsoft Word? How does it figure out where to wrap so that the line length stays consistent? Dynamic programming!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb0dff-b3e3-42c1-b2a2-1ece36202d20",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ce9cf-76f5-44f8-980d-82fcc5202934",
   "metadata": {},
   "source": [
    "## K-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed911667-4846-4d5f-a812-edb1050e628d",
   "metadata": {},
   "source": [
    "The idea is quite simple. If we want to find out if a person is associated with one cluster or another, we simply find the k nearest neighbours of that person and the more neighbours a person has of a given cluster, the more likely it is that the person belongs to that cluster. \n",
    "\n",
    "We can use this for movie recommendations; the users within a cluster are defined to have similar tastes. So, they can be recommended the same things.\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/38.png width=350 />\n",
    "\n",
    "How do we graph the users by similarity?\n",
    "\n",
    "If we wanted to compare a grapefruit to an orange, we can choose a number of differentiating metrics such as size and colour. We then rate the items on these metrics and plot a graph of size vs colour. The Euclidean distance between two fruits tells us of their similarity.\n",
    "\n",
    "For the movie recommendations example, we can ask users to rate different genres, e.g. comedy, action drama, and use these in a multidimensional coordinate system. We now need to use a more generalised form of the Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d56caa-dde9-4657-8408-1566dcf81385",
   "metadata": {},
   "source": [
    "## Classification vs Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab8d95-8287-4dd5-9d08-d22e039f65d7",
   "metadata": {},
   "source": [
    "With KNN, there are two basic things you can do:\n",
    "- classification\n",
    "- regression\n",
    "\n",
    "If you want to figure out which cluster (class) a person belongs to, we use KNN for classification. We predict a class.\n",
    "If you want to predict what a user will recommend a given movie, given the recommendations of their k nearest neighbours, we are performing regression. We predict a number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83900c-9754-4a0f-b9f7-f0dee9fe71ec",
   "metadata": {},
   "source": [
    "We've already looked at a classification example. Let's look at a regression example:\n",
    "\n",
    "Consider owning a bakery and you want to determine how many loaves of bread you should make. You determine a number of metrics, such as weather, holiday/weekend or not, game on or not etc., and you count the number of loaves sold for a large range of days.\n",
    "\n",
    "If there are 3 metrics then, for each day, we'll have a 3 dimensional coordinate and a number that corresponds to the number of loaves sold.\n",
    "\n",
    "Regression asks us for a coordinate and uses that to predict the number of loaves.\n",
    "\n",
    "To make this prediction, we could calculate the Euclidean lengths for all coordinates and look for the k closest lengths to the coordinate's length that we've asked for. Then, we find the associated number of loaves sold for those k neighbours and calculate the average. This is how many loaves we should make.\n",
    "\n",
    "Quick notes:\n",
    "- We've been mentioning the euclidean distance, but the **cosine similarity** is another popular one. It is the dot product formula rearranged for cos(theta).\n",
    "- Asking users to rate something is not always a good idea due to their own bias. Instead, you could also consider how long they spend watching different genres.\n",
    "- How do you determine what k should be in KNN? A rule of thumb is, if you have N users, you should look at sqrt(N) neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840e305-77fa-44aa-bfc8-e3bb288ddd76",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3699b-3365-4ec7-985b-d87fefb764ca",
   "metadata": {},
   "source": [
    "This is going to be concise, because you already know most of it.\n",
    "\n",
    "Naive Bayes Classifier is a simple algorithm. You classify a whole by first breaking into many parts and seeing what those parts generally belong to, and using that to predict the whole.\n",
    "\n",
    "For example, a spam filter using this algorithm may see all the words used in an email. During some training stage, it would have learnt that, say, 50% of emails containing the word 'millions' are spam. It can look up the probabilities of spam for all words in that email and use that to determine whether the email as a whole is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb09a88-82c1-4d8a-ac5b-a71e4e8e0ff3",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Section 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42491554-7ed8-4b59-9735-fe957ae12da2",
   "metadata": {},
   "source": [
    "This section will briefly overview a few algorithms that weren't covered but may be very important, such as binary search trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e38b1-b9a2-4eb2-a6e2-927c6b41cd25",
   "metadata": {},
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948931ba-b194-4033-8137-7d8ac2b37324",
   "metadata": {},
   "source": [
    "Earlier we looked at binary searches to see whether a user exists on Facebook. This only works with a sorted array. But what if a new user joins? We would have to find the exact right place to insert them which may take long. A way around this is to use a **binary search tree** (BST)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfe93d9-a871-4c03-a1bb-a556c9d12718",
   "metadata": {},
   "source": [
    "<img src=Grokking-Algorithms-Images/39.png width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e15202-a29e-41b7-bf93-d5bd20f19c1a",
   "metadata": {},
   "source": [
    "For every node, the nodes to its left are smaller in value, and the nodes to the right are larger in value.\n",
    "\n",
    "If you want to look for Maggie, you first see if Maggie > David: Yes, so go to the right. Then, see if Maggie > Manning: No, so go to the left.\n",
    "\n",
    "BSTs take O(logn) on average and O(n) in the worst case. Although, sorted arrays (which we use for regular binary searches) take O(logn) in the *worst* case, making it faster on average, it is much slower for insertions and deletions on average. Here are the times for BST andd arrays:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/40.png width=400 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da5f87-30e0-4476-928b-146ca10b9eec",
   "metadata": {},
   "source": [
    "BSTs have downsides too:\n",
    "\n",
    "- They don't have random access like BST.\n",
    "- The performance times rely on the tree being balanced (not left-/right-leaning. But, there are special BSTs such as the red-black tree that balance themselves.\n",
    "\n",
    "A degenerate tree is an unbalanced tree, which if entirely one-sided, is essentially a linked list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f74d1f-a5a4-4541-8472-3f59fbae10c3",
   "metadata": {},
   "source": [
    "When are BSTS used?\n",
    "\n",
    "- B-trees are another special type, commonly used to store data in databases, alongside red-black trees, heaps, and splay trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24963302-33ce-4161-9631-94df7a9562cf",
   "metadata": {},
   "source": [
    "## Inverted Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce225313-4b0d-416f-ac38-3340aaba3172",
   "metadata": {},
   "source": [
    "These are commonly used for search engines. Let's say you have 3 webpages:\n",
    "\n",
    "<img src=Grokking-Algorithms-Images/41.png width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d3e3d-0af4-4958-b5ac-79cc55e8fd79",
   "metadata": {},
   "source": [
    "First, we can take every unique word across these pages and use them as keys in a hash table. The values are a list of all the webpages that they appear in. For this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4cf0ba8-933b-442b-bade-85f9e189324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {\n",
    "    'hi': ['A', 'B'],\n",
    "    'there': ['A', 'C'],\n",
    "    'adit': ['B'],\n",
    "    'we': ['C'],\n",
    "    'go': ['C']\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17433806-e1fe-41ab-a566-7c084ff65698",
   "metadata": {},
   "source": [
    "This is the inverted index data structure: a hash that maps words to places where they appear.\n",
    "\n",
    "The next algorithm is the fourier transform which we know all about, so I'm ignoring it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d180f-ed0c-4c48-9c4c-708a2bd65ea5",
   "metadata": {},
   "source": [
    "## Parallel Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222e461-94d5-4654-ab2f-74390fe891e3",
   "metadata": {},
   "source": [
    "The next three topics are about scalability and working with a lot of data. These take advantage of the multiple cores on a CPU. . It’s well known that you can’t sort an array in O(n) time—unless you use a parallel algorithm! There’s a parallel version of quicksort that will sort an array in O(n) time. \n",
    "\n",
    "Parallel algorithms are hard to design. And it’s also hard to make sure they work correctly and to figure out what type of speed boost you’ll see. One thing is for sure—the time gains aren’t linear. So if you have two cores in your laptop instead of one, that almost never means your algorithm will magically run twice as fast. There are a couple of reasons for this:\n",
    "\n",
    "- Overhead of managing the parallelism—Suppose you have to sort an array of 1,000 items. How do you divide this task among the two cores? Do you give each core 500 items to sort and then merge the two sorted arrays into one big sorted array? Merging the two arrays takes time.\n",
    "\n",
    "- Load balancing—Suppose you have 10 tasks to do, so you give each core 5 tasks. But core A gets all the easy tasks, so it’s done in 10 seconds, whereas core B gets all the hard tasks, so it takes a minute. That means core A was sitting idle for 50 seconds while core B was doing all the work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ce879-d634-4746-8599-5fb40074ed2c",
   "metadata": {},
   "source": [
    "## MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a29eef-b12a-4d2d-978e-058de9b243bc",
   "metadata": {},
   "source": [
    "Distributed algorithms are great when you have a lot of work to do and want to speed up the time required to do it. MapReduce in particular is built up from two simple ideas: the map function and the reduce function. There’s a special type of parallel algorithm that is becoming increasingly\n",
    "popular: the distributed algorithm. It’s fine to run a parallel algorithm on your laptop if you need two to four cores, but what if you need hundreds of cores? Then you can write your algorithm to run across multiple machines. The MapReduce algorithm is a popular distributed algorithm. \n",
    "\n",
    "MapReduce in particular is built up from two simple ideas: the map function and the reduce function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ea290-ed80-41d0-8aa7-3e946972c5df",
   "metadata": {},
   "source": [
    "The map function is simple: it takes an array and applies the same function to each item in the array. If the array is extremely large, we could divide it up and give it to different cores.\n",
    "\n",
    "The reduce function transforms an array to a single item. It applies a function to the first two items and reduces them to one. This number is then paired with the subsequent number and the function is applied again, reducing them to a single number. Repeat this process until only one number remains.\n",
    "\n",
    "Using these two functions together can result in extremely fast querying of data. \n",
    "\n",
    "There are a few other algorithms mentioned in this section but are too brief to write here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c2490-c180-499a-b8bc-82a40a0e58a3",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8002a2e-28da-464b-8b47-3a5c21125ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
